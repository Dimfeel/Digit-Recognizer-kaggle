{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (28, 28)\n",
    "IMAGE_SHAPE = (*IMAGE_SIZE, 1)\n",
    "\n",
    "RESIZE_SIZE = (224, 224)\n",
    "RESIZE_SHAPE = (*RESIZE_SIZE, 1)\n",
    "\n",
    "EPOCHS = 75\n",
    "DROP_RATE = 0.4\n",
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "RESIZE_SIZE = (224, 224)\n",
    "TTA_COUNT = 10\n",
    "\n",
    "MODEL_VERSION = 'V17'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TPU Detection\n",
    "\n",
    "To run ResNet50, TPU is mandatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is set.\n",
    "    # On Kaggle this is always the case.\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'digit-recognizer/'\n",
    "\n",
    "def read_data(file_name):\n",
    "    file_path = DATA_DIR + file_name\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = read_data('train.csv')\n",
    "\n",
    "print('Train shape: ', train_data.shape)\n",
    "\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(data):\n",
    "    images_data = data.loc[ : , 'pixel0':'pixel783' ]\n",
    "    images_array = images_data.to_numpy(dtype=np.uint8)\n",
    "    images = images_array.reshape(-1, *IMAGE_SHAPE)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(data_data):\n",
    "    labels = data_data['label'].to_numpy(dtype=np.int8)\n",
    "    return labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_images(train_data)\n",
    "Y = get_labels(train_data)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize Image\n",
    "\n",
    "The bigger image size, the better accuracy. To resize, Image.resize() with LANCZOS filter is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def resize_image(orig_np):\n",
    "    reshape_np = np.reshape(orig_np, IMAGE_SIZE)\n",
    "    orig_im = Image.fromarray(reshape_np)\n",
    "    resized_im = orig_im.resize(RESIZE_SIZE, Image.LANCZOS)\n",
    "    resized_np = np.asarray(resized_im, dtype=np.uint8)\n",
    "    resized_reshaped_np = np.reshape(resized_np, RESIZE_SHAPE)\n",
    "    return resized_reshaped_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(orig_nps):\n",
    "    n_images = orig_nps.shape[0]\n",
    "    resized_shape = (n_images, *RESIZE_SHAPE)\n",
    "    resized_nps = np.empty(resized_shape, dtype=np.uint8)\n",
    "\n",
    "    for i in range(n_images):\n",
    "        if i % 100 == 0:\n",
    "            print('.', end='', flush=True)\n",
    "        x_np = orig_nps[i]\n",
    "        resized_nps[i] = resize_image(x_np)\n",
    "    print()\n",
    "    \n",
    "    return resized_nps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resized = resize_images(X)\n",
    "\n",
    "print(X_resized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_image(image, title=None, subplot=(1, 1, 1)):\n",
    "    plt.subplot(*subplot)\n",
    "    image_shape = (image.shape[0], image.shape[1])\n",
    "    reshaped_image = image.reshape(image_shape)\n",
    "    plt.imshow(reshaped_image, cmap='gray')\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plot_image(X[1], 'Original image', (2,2,1))\n",
    "plot_image(X_resized[1], 'Resized image', (2,2,2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Argmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometric Transform\n",
    "\n",
    "The methods below are taken from [Rotation Augmentation GPU/TPU - [0.96+]](https://www.kaggle.com/cdeotte/rotation-augmentation-gpu-tpu-0-96)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "import math\n",
    "\n",
    "def get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n",
    "    # returns 3x3 transformmatrix which transforms indicies\n",
    "        \n",
    "    # CONVERT DEGREES TO RADIANS\n",
    "    rotation = math.pi * rotation / 180.\n",
    "    shear = math.pi * shear / 180.\n",
    "    \n",
    "    # ROTATION MATRIX\n",
    "    c1 = tf.math.cos(rotation)\n",
    "    s1 = tf.math.sin(rotation)\n",
    "    one = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    rotation_matrix = tf.reshape( tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3] )\n",
    "        \n",
    "    # SHEAR MATRIX\n",
    "    c2 = tf.math.cos(shear)\n",
    "    s2 = tf.math.sin(shear)\n",
    "    shear_matrix = tf.reshape( tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3] )    \n",
    "    \n",
    "    # ZOOM MATRIX\n",
    "    zoom_matrix = tf.reshape( tf.concat([one/height_zoom,zero,zero, zero,one/width_zoom,zero, zero,zero,one],axis=0),[3,3] )\n",
    "    \n",
    "    # SHIFT MATRIX\n",
    "    shift_matrix = tf.reshape( tf.concat([one,zero,height_shift, zero,one,width_shift, zero,zero,one],axis=0),[3,3] )\n",
    "    \n",
    "    return K.dot(K.dot(rotation_matrix, shear_matrix), K.dot(zoom_matrix, shift_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_transform(image,label):\n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly rotated, sheared, zoomed, and shifted\n",
    "#     DIM = IMAGE_SIZE[0]\n",
    "    DIM = RESIZE_SIZE[0]\n",
    "    XDIM = DIM%2 #fix for size 331\n",
    "    \n",
    "    rot = 10. * tf.random.normal([1],dtype='float32')\n",
    "    shr = 5. * tf.random.normal([1],dtype='float32') \n",
    "    h_zoom = 1.0 + tf.random.normal([1],dtype='float32')/10.\n",
    "    w_zoom = 1.0 + tf.random.normal([1],dtype='float32')/10.\n",
    "    h_shift = DIM * 0.05 * tf.random.normal([1],dtype='float32') \n",
    "    w_shift = DIM * 0.05 * tf.random.normal([1],dtype='float32') \n",
    "  \n",
    "    # GET TRANSFORMATION MATRIX\n",
    "    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n",
    "    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n",
    "    z = tf.ones([DIM*DIM],dtype='int32')\n",
    "    idx = tf.stack( [x,y,z] )\n",
    "    \n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(m,tf.cast(idx,dtype='float32'))\n",
    "    idx2 = K.cast(idx2,dtype='int32')\n",
    "    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n",
    "    \n",
    "    # FIND ORIGIN PIXEL VALUES           \n",
    "    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n",
    "    d = tf.gather_nd(image,tf.transpose(idx3))\n",
    "        \n",
    "#     return tf.reshape(d,[DIM,DIM,3]),label\n",
    "    return tf.reshape(d,[DIM,DIM,1]),label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cutout\n",
    "\n",
    "The paper is [here](https://arxiv.org/abs/1708.04552)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randints(shape, minval, maxval):\n",
    "    # maxval+1 to include maxval for the result.\n",
    "    # generated range is [minval, maxval) (maxval is not included)\n",
    "    return tf.random.uniform(\n",
    "        shape=shape, minval=minval, maxval=maxval+1, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_range_mask(size, start, end):\n",
    "    indice = tf.range(size, dtype=tf.int32)\n",
    "    start_mask = (start <= indice)\n",
    "    end_mask = (indice <= end)\n",
    "    range_mask = start_mask & end_mask\n",
    "    return range_mask\n",
    "\n",
    "def make_region_mask(image_height, image_width, top, left, bottom, right):\n",
    "    row_mask = make_range_mask(image_height, top, bottom)\n",
    "    col_mask = make_range_mask(image_width, left, right)\n",
    "    region_mask = row_mask[ ... , tf.newaxis] & col_mask[ tf.newaxis, ... ]\n",
    "    reshaped_region_mask = region_mask[ ..., tf.newaxis]\n",
    "    return reshaped_region_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_cutout(orig_image, label):\n",
    "    # At most mask_ratio * mask_ratio = 0.25 of image is cut.\n",
    "    mask_ratio = 0.5\n",
    "    \n",
    "    image_shape = tf.shape(orig_image)\n",
    "    image_height = image_shape[0]\n",
    "    image_width = image_shape[1]\n",
    "    mask_h = tf.cast(tf.cast(image_height, tf.float32) * mask_ratio, tf.int32)\n",
    "    mask_w = tf.cast(tf.cast(image_width, tf.float32) * mask_ratio, tf.int32)\n",
    "    mask_value = 0.0\n",
    "\n",
    "    top = randints([], -mask_h // 2, image_height - mask_h // 2)\n",
    "    left = randints([], -mask_w // 2, image_width - mask_w // 2)\n",
    "    bottom = top + mask_h\n",
    "    right = left + mask_w\n",
    "\n",
    "    cut_region = make_region_mask(\n",
    "        image_height, image_width, top, left, bottom, right)\n",
    "    cutout_image = tf.where(cut_region, mask_value, orig_image)\n",
    "    return cutout_image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Dataset\n",
    "\n",
    "To feed data to the model runs on TPU, tensorflow dataset is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_y = np.unique(Y)\n",
    "label_count = len(unique_y)\n",
    "\n",
    "print(unique_y)\n",
    "print(label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "def make_dataset(\n",
    "        X_np, y_np,\n",
    "        transform=False, cutout=False, repeat=False, shuffle=False):\n",
    "    def _cast_to_float(x, y):\n",
    "        return tf.cast(x, tf.float32), y\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X_np, y_np))\n",
    "    ds = ds.map(_cast_to_float, num_parallel_calls=AUTO)\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(2048)\n",
    "    if transform:\n",
    "        ds = ds.map(do_transform, num_parallel_calls=AUTO)\n",
    "    if cutout:\n",
    "        ds = ds.map(do_cutout, num_parallel_calls=AUTO)\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "    if repeat:\n",
    "        ds = ds.repeat()\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_ds(X_np, y_np):\n",
    "    ds = make_dataset(\n",
    "        X_np, y_np, transform=True, cutout=True, repeat=True, shuffle=True)\n",
    "    return ds\n",
    "\n",
    "def make_val_ds(X_np, y_np):\n",
    "    ds = make_dataset(\n",
    "        X_np, y_np, transform=False, cutout=False, repeat=False, shuffle=False)\n",
    "    return ds\n",
    "\n",
    "def make_test_ds(X_np):\n",
    "    # Make dummy labals, because there are no labels for test data.\n",
    "    y_np = np.zeros(X_np.shape[0], dtype=np.int32)\n",
    "    # Only geometric transform is applied for Test Time Augmentation.\n",
    "    ds = make_dataset(\n",
    "        X_np, y_np, transform=True, cutout=False, repeat=False, shuffle=False)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "\n",
    "To utilize all the training data, 5 fold cross validation is used. To split the data,  [sklearn.model_selection.StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "NFOLD = 5\n",
    "k_fold = StratifiedKFold(n_splits=NFOLD)\n",
    "\n",
    "fold_index_list = []\n",
    "for train_index, val_index in k_fold.split(X_resized, Y):\n",
    "    fold_index_list.append((train_index, val_index))\n",
    "\n",
    "def get_fold(fold_i):\n",
    "    train_index, val_index = fold_index_list[fold_i]\n",
    "    X_train, y_train = X_resized[train_index], Y[train_index]\n",
    "    X_val, y_val = X_resized[val_index], Y[val_index]\n",
    "    \n",
    "    train_ds = make_train_ds(X_train, y_train)\n",
    "    val_ds = make_val_ds(X_val, y_val)\n",
    "    return train_ds, val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_steps_per_epoch(fold_i):\n",
    "    train_index, val_index = fold_index_list[fold_i]\n",
    "    steps_per_epoch = (len(train_index) + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "    return steps_per_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw Sample Images\n",
    "\n",
    "Let's see some sample images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = 10; col = 10;\n",
    "orig_ds = make_dataset(\n",
    "    X_resized[ :row], None, transform=False,\n",
    "    cutout=False, repeat=False, shuffle=True).unbatch()\n",
    "\n",
    "plt.figure(figsize=(1.5 * col, 1.5 * row))\n",
    "for i, (orig_img, orig_label) in enumerate(iter(orig_ds)):\n",
    "    orig_elem_ds = tf.data.Dataset.from_tensors((orig_img, orig_label))\n",
    "    aug_elem_ds = orig_elem_ds.repeat(count=col - 1) \\\n",
    "        .map(do_transform).map(do_cutout)\n",
    "    plot_image(orig_img.numpy(), subplot=(row, col, i*col + 1))\n",
    "    for j, (aug_img, aug_label) in enumerate(iter(aug_elem_ds)):\n",
    "        plot_image(aug_img.numpy(), subplot=(row, col, i*col + j + 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Model\"></a>\n",
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ResNet50\"></a>\n",
    "### ResNet50\n",
    "\n",
    "ResNet50 with imagenet weights is used as the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.models as M\n",
    "\n",
    "MODEL_INPUT_SHAPE = (*RESIZE_SIZE, 3)\n",
    "\n",
    "def make_model(name):\n",
    "    with strategy.scope():\n",
    "        inputs = L.Input(shape=RESIZE_SHAPE, name=\"input\")\n",
    "        # Scale from 0..255 to 0..1\n",
    "        scaled = L.Lambda(lambda v: v / 255.0, name='scaling')(inputs)\n",
    "        # Makes 3 color channels from gray scale image.\n",
    "        img_input = L.Concatenate(name='concat')([scaled, scaled, scaled])\n",
    "        x = ResNet50(\n",
    "            include_top=False, weights='imagenet',\n",
    "            input_shape=MODEL_INPUT_SHAPE, pooling='avg')(img_input)\n",
    "        x = L.Dropout(DROP_RATE, name=\"dropout\")(x)\n",
    "        outputs = L.Dense(label_count, activation='sigmoid', name='classify')(x)\n",
    "        model = M.Model(inputs=inputs, outputs=outputs, name=name)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model('model')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"LearningRate\"></a>\n",
    "### Learning Rate\n",
    "\n",
    "The method below are taken from [Rotation Augmentation GPU/TPU - [0.96+]](https://www.kaggle.com/cdeotte/rotation-augmentation-gpu-tpu-0-96). The original was exponential decay. I changed to cosine decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "LR_START = 0.00001\n",
    "LR_MAX = 0.00005 * strategy.num_replicas_in_sync\n",
    "LR_MIN = 0.00001\n",
    "LR_RAMPUP_EPOCHS = min(5, EPOCHS // 5)\n",
    "LR_SUSTAIN_EPOCHS = 0\n",
    "\n",
    "def lrfn(epoch):\n",
    "    if epoch < LR_RAMPUP_EPOCHS:\n",
    "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
    "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
    "        lr = LR_MAX\n",
    "    else:\n",
    "        decay_total_epochs = EPOCHS - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS\n",
    "        decay_epoch_index = epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS\n",
    "        phase = math.pi * decay_epoch_index / decay_total_epochs\n",
    "        cosine_decay = 0.5 * (1 + math.cos(phase))\n",
    "        lr = (LR_MAX - LR_MIN) * cosine_decay + LR_MIN\n",
    "    return lr\n",
    "\n",
    "def make_lr_callback():\n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = False)\n",
    "    return lr_callback\n",
    "\n",
    "rng = [i for i in range(EPOCHS)]\n",
    "lr_y = [lrfn(x) for x in rng]\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(rng, lr_y)\n",
    "print(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\". \\\n",
    "      format(lr_y[0], max(lr_y), lr_y[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ModelCheckPoint\"></a>\n",
    "### Model Check Point\n",
    "\n",
    "Saves the best model according to val_accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_best_model_file_path(fold_i):\n",
    "    file_name = \"best_model_{0}_{1}.hdf5\".format(MODEL_VERSION, fold_i)\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "def make_model_check_point(fold_i):\n",
    "    best_model_file_path = make_best_model_file_path(fold_i)\n",
    "    return ModelCheckpoint(\n",
    "        best_model_file_path, monitor='val_accuracy', mode='max',\n",
    "        verbose=0, save_best_only=True, save_weights_only=False, period=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"InitialWeights\"></a>\n",
    "### Initial Weights\n",
    "\n",
    "Saves initial weights to reset the model to the initial state. Making new model would be better for variety, however, it took more time than loading initial weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weights_file_path = \"initial_weights.hdf5\"\n",
    "\n",
    "model.save_weights(initial_weights_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Training\"></a>\n",
    "## Training\n",
    "\n",
    "Train the models with cross validation data. Then, draw plots for loss and accuracy to check the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_list = []\n",
    "for fold_i in range(NFOLD):\n",
    "    print(\"#\" * 40)\n",
    "    print(\"# Fold {0}\".format(fold_i))\n",
    "    \n",
    "    train_ds, val_ds = get_fold(fold_i)\n",
    "    steps_per_epoch = calc_steps_per_epoch(fold_i)\n",
    "    lr_callback = make_lr_callback()\n",
    "    check_point = make_model_check_point(fold_i)\n",
    "\n",
    "    model.load_weights(initial_weights_file_path)\n",
    "    history = model.fit(\n",
    "        train_ds, epochs=EPOCHS, steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=val_ds,\n",
    "        callbacks=[lr_callback, check_point], verbose=0)\n",
    "    history_list.append(history)\n",
    "\n",
    "    best_acc = max(history.history['accuracy'])\n",
    "    best_val_acc = max(history.history['val_accuracy'])\n",
    "    print(\n",
    "        \"Fold {0}: accuracy={1:.5f}, val_accuracy={2:.5f}\".format(\n",
    "        fold_i, best_acc, best_val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, title, labels, ylim, subplot):\n",
    "    plt.subplot(*subplot)\n",
    "    plt.title(title)\n",
    "    for label in labels:\n",
    "        plt.plot(history.history[label], label=label)\n",
    "    plt.ylim(ylim)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = len(history_list)\n",
    "plt.figure(figsize=(15, 4 * n_rows))\n",
    "for i, history in enumerate(history_list):\n",
    "    plot_history(\n",
    "        history, \"Loss\", ['loss', 'val_loss'],\n",
    "        (0.0, 0.2), (n_rows, 2, 2*i + 1))\n",
    "    plot_history(\n",
    "        history, \"Accuracy\", ['accuracy', 'val_accuracy'],\n",
    "        (0.98, 1.0), (n_rows, 2, 2*i + 2))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Prediction\"></a>\n",
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"TestData\"></a>\n",
    "### Test Data\n",
    "\n",
    "Read CSV file for the test data, get images and resize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = read_data('test.csv')\n",
    "\n",
    "print('Test shape: ', test_data.shape)\n",
    "\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = get_images(test_df)\n",
    "\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_resized = resize_images(X_test)\n",
    "\n",
    "print(X_test_resized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_val_pred_file_path(fold_i):\n",
    "    file_name = \"val_pred_{0}_{1}\".format(MODEL_VERSION, fold_i)\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"TestTimeAugmentation\"></a>\n",
    "### Test Time Augmentation\n",
    "\n",
    "Predict the test images 10 times with augmented data. This reduces the result fluctuation. To augment the data, geometric transform is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_pred = np.zeros((X_test_resized.shape[0], label_count))\n",
    "for fold_i in range(NFOLD):\n",
    "    best_model_file_path = make_best_model_file_path(fold_i)\n",
    "    model.load_weights(best_model_file_path)\n",
    "\n",
    "    train_ds, val_ds = get_fold(fold_i)\n",
    "    val_pred = model.predict(val_ds)\n",
    "    val_pred_file_name = make_val_pred_file_path(fold_i)\n",
    "    np.save(val_pred_file_name, val_pred)\n",
    "    \n",
    "    test_ds = make_test_ds(X_test_resized)\n",
    "    print(\"Fold {0}\".format(fold_i), end='', flush=True)\n",
    "    for i in range(TTA_COUNT):\n",
    "        print('.', end='', flush=True)\n",
    "        model_pred += model.predict(test_ds)\n",
    "    print()\n",
    "        \n",
    "y_pred = np.argmax(model_pred, axis=1)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Submit\"></a>\n",
    "### Submit\n",
    "\n",
    "Submit the prediction result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = read_df('sample_submission.csv')\n",
    "\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['Label'] = y_pred\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "!head submission.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
